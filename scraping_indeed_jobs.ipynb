{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Job Discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm getting ready to start looking for a new job (my term at the Federal Reserve Board lasts 2 years), so I've been trying to reflect on what's important to me. I could write thousands of words about how I want to challenge myself intellectually, make a difference in people's lives, work with smart and passionate people, and many other things -- but I won't.\n",
    "\n",
    "Though that is how I'm going to look for jobs -- seeking out and applying to specific jobs that I've identified as a strong fit based on my skillset and desire for self-actualization -- I'm not even **close** to a good enough writer to make such a post remotely readable.\n",
    "\n",
    "So, instead, this post will be about the opposite side of the job search: finding potentially interesting jobs from the abyss that I might not have otherwise seen. I'll focus on [Indeed.com](http://www.indeed.com/), a major job aggregator that is one of the top stops in many people's job search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so there are thousands of jobs posted to Indeed.com every day. It's ridiculous to think I could go through them all and evaluate whether I'm a good fit for every single job. It would take forever.\n",
    "\n",
    "So I need to create some kind of automated pipeline that will:\n",
    "    1) Sift through the recent job results on Indeed\n",
    "    2) Evaluate each of the jobs\n",
    "    3) Identify the ones that are relevant to me\n",
    "    4) Email me a list of the recent jobs that are relevant to me every day.\n",
    "\n",
    "Then I'll stick this in my crontab and just check my email every day for new data science jobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I want to be able to control many of the parameters (including the job search terms), I'm going to build this pipeline through a series of stand-alone functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Single Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's not easy to perfectly evaluate any data science job, it's fairly trivial to see if it's remotely relevant to my skillset. For example, if I were 100% focused on getting a job requiring Python programming, I probably wouldn't apply to jobs whose descriptions didn't have the word Python in them. By using this (simple) heuristic, I can write a function to do the evaluation for me. The function will need to search the HTML of a job page and return whether or not I'm a good match. Based on the example logic, I'll write the function to check if Python, R, or SQL are in the job description and return the number of times those terms appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "import time\n",
    "import requests\n",
    "import smtplib\n",
    "\n",
    "def evaluate_job(job_url):\n",
    "    try:\n",
    "        job_html = requests.request('GET', job_url, timeout = 10)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "    job_soup = bs4.BeautifulSoup(job_html.content, 'lxml')\n",
    "    soup_body = job_soup('body')[0]\n",
    "    \n",
    "    python_count = soup_body.text.count('Python') + soup_body.text.count('python')\n",
    "    sql_count = soup_body.text.count('SQL') + soup_body.text.count('sql')\n",
    "    r_count = len(re.findall('R[\\,\\.]', soup_body.text)) # this one's not perfect, but I blame R's name\n",
    "    skill_count = python_count + sql_count + r_count\n",
    "    print 'R count: {0}, Python count: {1}, SQL count: {2}'.format(r_count, python_count, sql_count)\n",
    "    \n",
    "    return skill_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate a sample job page. How about the [Senior Associate Data Scientist position at Illinois Technology Association](http://www.jobs.net/jobs/ita/en-us/job/United-States/Senior-Associate-Data-Scientist/J3H08S62X9XZZTYDXJP/), the first non-sponsored result on my Indeed.com results page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R count: 1, Python count: 1, SQL count: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_job('http://www.jobs.net/jobs/ita/en-us/job/United-States/Senior-Associate-Data-Scientist/J3H08S62X9XZZTYDXJP/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! I got hits for R, Python, and SQL. Looks like this function is working (and that I might be a good fit for this job)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Job Data from a single Indeed.com Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function to evaluate a job, we need a function to get the list of jobs to evaluate from a page on Indeed.com. I don't just want the URL (though that's all I need to evaluate the job), since I'm also interested in attributes like the title, company name, and date the job was posted.\n",
    "\n",
    "Using `requests` and `beautifulsoup` again, I can extract the non-sponsored jobs on every page. These jobs have a special attribute in their `<div>` statement, `data-tn-component=\"organicJob\"`, which let's me get them pretty easily. Then, I just extract the relevant attributes for each job (as a dictionary) and return a list of the job dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_job_data_from_indeed(base_url):\n",
    "    response = requests.get(base_url)\n",
    "    soup = bs4.BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    tags = soup.find_all('div', {'data-tn-component' : \"organicJob\"})\n",
    "    companies_list = [x.span.text for x in tags]\n",
    "    attrs_list = [x.h2.a.attrs for x in tags]\n",
    "    dates = [x.find_all('span', {'class':'date'}) for x in tags]\n",
    "    \n",
    "    # update attributes dictionaries with company name and date posted\n",
    "    [attrs_list[i].update({'company': companies_list[i].strip()}) for i, x in enumerate(attrs_list)]\n",
    "    [attrs_list[i].update({'date posted': dates[i][0].text.strip()}) for i, x in enumerate(attrs_list)]\n",
    "    return attrs_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a sample job attribute dictionary (the first one on the page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': ['turnstileLink'],\n",
       " 'company': u'Illinois Technology Association',\n",
       " 'data-tn-element': 'jobTitle',\n",
       " 'date posted': u'Just posted',\n",
       " 'href': '/rc/clk?jk=f858e2d65923d3fc&fccid=3de83442785d5fca',\n",
       " 'itemprop': 'title',\n",
       " 'onclick': 'setRefineByCookie([]); return rclk(this,jobmap[0],true,0);',\n",
       " 'onmousedown': 'return rclk(this,jobmap[0],0);',\n",
       " 'rel': ['nofollow'],\n",
       " 'target': '_blank',\n",
       " 'title': 'Senior Associate, Data Scientist'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_job_data_from_indeed('http://www.indeed.com/jobs?q=data+scientist&l=New+York%2C+NY&sort=date')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! There's some extraneous information in here, but I'm not that worried about memory usage so it's not an issue. I've got the company name, date posted, hyperlink to the job, and the job title. I'm good to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding and Evaluating all the New Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these functions in hand, I'm almost ready to find and evaluate new jobs. So far I've only evaluated jobs based on the programming languages. This makes sense, since I'm interested in data science, but I might also be interested in jobs at specific companies (regardless of the job description). I'll make a list of these companies and I'll use it as another way to evaluate a job. If a company name matches one in the list, I'll treat it as a relevant job. As an example, I'll just pick the big five US tech companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extra_interest_companies = ['apple', 'microsoft', 'google', 'facebook', 'amazon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I can extract job information from a page on Indeed, and then I can evaluate the individual jobs from their URLs. Now I need to loop through Indeed.com and apply my functions to every page. I'll define a function `find_new_jobs` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_new_jobs(days_ago_limit = 1, starting_page = 0, pages_limit = 20, old_jobs_limit = 5,\n",
    "                  location = 'New York, NY', query = 'data scientist'):\n",
    "    \n",
    "    query_formatted = re.sub(' ', '+', query)\n",
    "    location_formatted = re.sub(' ', '+', location)\n",
    "    indeed_url = 'http://www.indeed.com/jobs?q={0}&l={1}&sort=date&start='.format(query_formatted, location_formatted)\n",
    "    old_jobs_counter = 0\n",
    "    new_jobs_list = []\n",
    "    \n",
    "    for i in xrange(starting_page, starting_page + pages_limit):\n",
    "        if old_jobs_counter >= old_jobs_limit:\n",
    "            break\n",
    "        \n",
    "        print 'URL: {0}'.format(indeed_url + str(i*10)), '\\n'\n",
    "\n",
    "        # extract job data from Indeed page\n",
    "        attrs_list = extract_job_data_from_indeed(indeed_url + str(i*10))\n",
    "        \n",
    "        # loop through each job, breaking out if we're past the old jobs limit\n",
    "        for j in xrange(0, len(attrs_list)): \n",
    "            if old_jobs_counter >= old_jobs_limit:\n",
    "                break\n",
    "\n",
    "            href = attrs_list[j]['href']\n",
    "            title = attrs_list[j]['title']\n",
    "            company = attrs_list[j]['company']\n",
    "            date_posted = attrs_list[j]['date posted']\n",
    "            \n",
    "            # if posting date is beyond the limit, add to the counter and skip\n",
    "            try:\n",
    "                if int(date_posted[0]) >= days_ago_limit:\n",
    "                    print 'Adding to old_jobs_counter.'\n",
    "                    old_jobs_counter+= 1\n",
    "                    continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            print '{0}, {1}, {2}'.format(repr(company), repr(title), repr(date_posted))\n",
    "\n",
    "            # evaluate the job\n",
    "            evaluation = evaluate_job('http://indeed.com' + href)\n",
    "            \n",
    "            if evaluation >= 1 or company.lower() in extra_interest_companies:\n",
    "                new_jobs_list.append('{0}, {1}, {2}'.format(company, title, 'http://indeed.com' + href))\n",
    "                \n",
    "            print '\\n'\n",
    "            time.sleep(5)\n",
    "            \n",
    "    new_jobs_string = '\\n\\n'.join(new_jobs_list)\n",
    "    return new_jobs_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's some extra stuff in there to be respectful of Indeed's servers and to make sure I'm only evaluating recent jobs, but essentially it's just a loop around the two functions I created earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emailing Myself the New Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one weird thing about the function I defined just now is the output. I had a list of jobs, where each element in the list is a tuple in the format of `(company name, job title, url)`, but I returned it as a string (separated by two new lines). By returning the jobs in this format, it will look better when I email it to myself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `smtplib` library makes emailing really easy. I'll wrap the code into a function so I can send emails easily in different scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def send_gmail(from_addr = '****', to_addr = '****',\n",
    "               location = 'New York, NY',\n",
    "               subject = 'Daily Data Science Jobs Update Scraped from Indeed', text = None):\n",
    "    \n",
    "    message = 'Subject: {0}\\n\\nJobs in: {1}\\n\\n{2}'.format(subject, location, text)\n",
    "\n",
    "    # login information\n",
    "    username = '****'\n",
    "    password = '****'\n",
    "    \n",
    "    # send the message\n",
    "    server = smtplib.SMTP('smtp.gmail.com:587')\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(username, password)\n",
    "    server.sendmail(from_addr, to_addr, message)\n",
    "    server.quit()\n",
    "    print 'Email sent.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we're all ready.\n",
    "\n",
    "Since I may want to import the functions I created into another program sometime, I want to make sure the code only runs when I execute the code as a stand-alone program, as opposed to if I import it into another program. The `if __name__ == \"__main__\"` let's me do just that.\n",
    "\n",
    "Time for a test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    print 'Scraping Indeed now.'\n",
    "\n",
    "    start_page = 0\n",
    "    page_limit = 2\n",
    "    location = 'New York, NY'\n",
    "    data_scientist_jobs = find_new_jobs(query = 'data scientist', starting_page = start_page,\n",
    "                                        location = location, pages_limit = page_limit, days_ago_limit = 1, old_jobs_limit = 5)\n",
    "    send_gmail(text = data_scientist_jobs, location = location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Indeed now.\n",
      "URL: http://www.indeed.com/jobs?q=data+scientist&l=New+York,+NY&sort=date&start=0 \n",
      "\n",
      "u'Illinois Technology Association', 'Data Scientist', u'Just posted'\n",
      "R count: 1, Python count: 1, SQL count: 2\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Senior Data Scientist', u'Just posted'\n",
      "R count: 1, Python count: 1, SQL count: 0\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Principal Quantitative Analyst', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Director Data Science - Machine Intelligence', u'Just posted'\n",
      "R count: 1, Python count: 1, SQL count: 3\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Sr. Quantitative Analyst', u'Just posted'\n",
      "R count: 1, Python count: 1, SQL count: 1\n",
      "\n",
      "\n",
      "u'Climb', 'Account Management Intern', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Magellan Research Group', 'College Graduates - NYC Research Analyst', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Selby Jennings', 'Catastrophe Risk Analyst - Quantitative', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Selby Jennings', 'Machine Learning Quant Analyst', u'Just posted'\n",
      "R count: 0, Python count: 1, SQL count: 0\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Data Science Manager', u'Just posted'\n",
      "R count: 1, Python count: 1, SQL count: 1\n",
      "\n",
      "\n",
      "URL: http://www.indeed.com/jobs?q=data+scientist&l=New+York,+NY&sort=date&start=10 \n",
      "\n",
      "u'Lux Research', 'Research Analyst - Flexible Electronics and Displays', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Rutgers University', 'Research Associate I', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Rutgers University', 'Temporary Research Assistant, Per Diem', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Shutterstock', 'Enterprise Data Architect', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'State Street', 'Quantitative Analyst, Risk and Advisory, Global Exchange, Officer', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Weill Cornell Medical College', 'Medical Assistant- Vitals', u'Just posted'\n",
      "R count: 2, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Selby Jennings', 'Credit Research Analyst', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Illinois Technology Association', 'Senior Staff Engineer', u'Just posted'\n",
      "R count: 0, Python count: 1, SQL count: 2\n",
      "\n",
      "\n",
      "u'Weill Cornell Medical College', 'Research Study Aide', u'Just posted'\n",
      "R count: 0, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "u'Weill Cornell Medical College', 'Research Technician I', u'Just posted'\n",
      "R count: 4, Python count: 0, SQL count: 0\n",
      "\n",
      "\n",
      "Email sent.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy. Here's a snapshot of the email I sent myself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![png](/images/convolutions/indeed_email_pic.png?raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can just stick this program into a cron-job and I'll get an email every day with newly posted data science jobs I might be interested in. If I want to get emails with jobs in other cities or from other Indeed.com search terms, I can just add a another `find_new_jobs` and `send_gmail` couplet to the `main` function. If anyone was wondering why I was writing all of this code in functions (instead of as a stand-alone program), that's the reason right there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is all pretty useful, it's important to remember that finding jobs this way is externally rather than internally oriented. It's looking at the set of all (many) possibilities and finding ones that might be relevant, as opposed to looking to see if there are any openings at the places that I find exciting.\n",
    "\n",
    "It's finding jobs that I might be a good technical fit for -- not jobs that might be a good fit for me. As a result, this should be seen as a supplement to a good job search."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
